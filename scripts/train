#!/usr/bin/env python3
import argparse
import torch
import sys
import numpy as np
import time
import torch.optim as optim
import sklearn.metrics as metrics
from torch import nn
from far_range_upsampling.models import model_dict
from far_range_upsampling.utils import LidarData, loss_dict
from torch.utils.data import DataLoader


def main(args):
    log_file = open(f"./checkpoints/{args.exp_name}_train.log", "w")

    device = torch.device("cuda")
    BS = torch.cuda.device_count() * 8

    print(f"Number of GPUs: {torch.cuda.device_count()}", file=sys.stdout)
    print(f"Number of GPUs: {torch.cuda.device_count()}", file=log_file)
    print(f"Batch size: {BS}", file=sys.stdout)
    print(f"Batch size: {BS}", file=log_file)

    # Load train dataset
    lidar_data = LidarData("tr", step_size=args.KNNstep)
    # Adjust batch size if train dataset is too small
    if lidar_data.point.shape[0] < BS:
        BS = lidar_data.point.shape[0]
    # Train data loader
    tr_data_loader = DataLoader(
        lidar_data,
        num_workers=8,
        batch_size=BS,
        shuffle=True,
        drop_last=True,
    )

    # Define the model to use. Refer to models.py
    model = nn.DataParallel(model_dict[args.model](batch_size=BS, device=device)).to(
        device
    )

    epochs = 10000
    # Define the loss function
    if args.loss == "focal":
        loss_func = loss_dict[args.loss](args.focal_thresh).to(device)
    elif args.loss == "combined":
        loss_func = loss_dict[args.loss](args.focal_thresh, args.focal_weight).to(
            device
        )
    else:
        loss_func = loss_dict[args.loss]().to(device)

    # Initial learning rate for Adam optimizer
    learning_rate = 0.001
    optim_net = optim.Adam(model.parameters(), lr=learning_rate)

    patience = 0
    patience_count = 0
    best_loss = np.inf
    for epoch in range(epochs):
        train_loss = 0.0
        count = 0.0
        prediction = []
        ground_truth = []
        idx = 0
        total_time = 0.0

        for point, data, label in tr_data_loader:
            point, data, label = point.to(device), data.to(device), label.to(device)

            start_time = time.time()

            # Generate prediction
            logits = model(point, data)
            preds = logits.flatten(start_dim=0, end_dim=1)

            # Calculate the loss and backpropagation
            loss = loss_func(logits, label)
            loss.backward(retain_graph=True)
            optim_net.zero_grad()
            optim_net.step()

            end_time = time.time()
            total_time += end_time - start_time

            # ground truth
            gt = label.flatten(start_dim=0, end_dim=1)

            count += BS
            train_loss += loss.item() * BS
            ground_truth.append(gt.cpu().numpy())
            prediction.append(preds.detach().cpu().numpy())
            idx += 1

        print("train total time is", total_time, file=sys.stdout)
        print("train total time is", total_time, file=log_file)
        ground_truth = np.concatenate(ground_truth)
        prediction = np.concatenate(prediction)

        # Classes defined by thresholding of the distance
        prediction_class = prediction.copy()
        ground_truth_class = ground_truth.copy()
        prediction_class[prediction < 1000] = 1
        prediction_class[prediction >= 1000] = 0
        ground_truth_class[ground_truth < 1000] = 1
        ground_truth_class[ground_truth >= 1000] = 0

        # Calculate metrics
        train_mae = metrics.mean_absolute_error(ground_truth, prediction)
        train_acc = metrics.balanced_accuracy_score(
            ground_truth_class, prediction_class
        )

        outstr = f"Epoch {epoch}, train MAE: {train_mae}, train accuracy: {train_acc} loss: {train_loss * 1.0 / count}"
        print(outstr, file=sys.stdout)
        print(outstr, file=log_file)

        if train_loss < best_loss:
            patience = 0
            best_loss = train_loss
            torch.save(model.state_dict(), f"checkpoints/{args.exp_name}_model.pt")

        patience += 1
        if patience > args.patience:
            if patience_count < 3:
                # Learning rate change after each patience
                patience = 0
                patience_count += 1
                learning_rate /= 10
                print("learning rate change", file=sys.stdout)
                print("learning rate change", file=log_file)
                optim_net = optim.Adam(model.parameters(), lr=learning_rate)
            else:
                # Early stopping after 4 patiences
                print("early stopping", file=sys.stdout)
                print("early stopping", file=log_file)
                break


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument(
        "--exp-name",
        type=str,
        help="Name of the experiment",
    )
    parser.add_argument(
        "--KNNstep",
        type=int,
        default=1,
        help="KNN step size",
    )
    parser.add_argument(
        "--patience",
        type=int,
        default=50,
        help="Patience",
    )
    parser.add_argument(
        "--model",
        type=str,
        choices=model_dict.keys(),
        help="Model to use for training",
    )
    parser.add_argument(
        "--loss",
        type=str,
        choices=loss_dict.keys(),
        help="Loss function",
    )
    parser.add_argument(
        "--focal-thresh",
        type=int,
        default=2000,
        help="Distance threhold required for focal loss for classification",
    )
    parser.add_argument(
        "--focal-weight",
        type=float,
        default=1,
        help="Weight of the focal loss in the combined loss",
    )

    args = parser.parse_args()

    main(args)
